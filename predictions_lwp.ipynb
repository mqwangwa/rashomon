{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION VARIABLES\n",
    "num_random_seeds = 5\n",
    "num_perturbed_models = 50\n",
    "\n",
    "test_size = 0.33\n",
    "validation_size = 0.20\n",
    "\n",
    "EPSILON = 0.1\n",
    "\n",
    "TARGET_VARIABLE = \"qualified_gagne_3\"\n",
    "prediction_output = \"predictions/obermeyer/linear_wp_\"+TARGET_VARIABLE+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"data/obermeyer/obermeyer_data_cleaned.csv\"\n",
    "features = ['dem_female', 'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1', 'dem_age_band_45-54_tm1',\n",
    "            'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1', 'hypertension_elixhauser_tm1', 'cost_dialysis_tm1',\n",
    "            'cost_emergency_tm1', 'cost_home_health_tm1', 'cost_ip_medical_tm1', 'cost_ip_surgical_tm1', 'cost_laboratory_tm1',\n",
    "            'cost_op_primary_care_tm1', 'cost_op_specialists_tm1', 'cost_op_surgery_tm1', 'cost_other_tm1', 'cost_pharmacy_tm1',\n",
    "            'cost_physical_therapy_tm1', 'cost_radiology_tm1', 'gagne_sum_tm1']\n",
    "other_variables = ['person_id', 'gagne_sum_t', 'cost_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_source)\n",
    "X = df[features+other_variables]\n",
    "y = df[TARGET_VARIABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model_coefficients(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_weights(baseline_weights, epsilon):\n",
    "    random_vector = np.random.randn(*baseline_weights.shape)\n",
    "    random_vector = random_vector / np.linalg.norm(random_vector)\n",
    "    perturbation = np.random.uniform(0, epsilon) * random_vector\n",
    "    w = baseline_weights + perturbation\n",
    "    if distance.euclidean(w, baseline_weights) > epsilon:\n",
    "        print(f\"L2 norm {distance.euclidean(w, baseline_weights)} more than {epsilon} away\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_columns(X_test, baseline_weights, epsilon):\n",
    "    predictions = []\n",
    "    columns = []\n",
    "    for i in tqdm(range(num_perturbed_models)):\n",
    "        perturbed_weights = get_perturbed_weights(baseline_weights, epsilon)\n",
    "        predictions.append(np.dot(X_test, perturbed_weights))\n",
    "        columns.append(f'm_{i+1}')\n",
    "    return predictions, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred)** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 0\n",
      "baseline training_loss 2981.304928434374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 146.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too much error 42 models\n",
      "random seed 1\n",
      "baseline training_loss 2954.6509778635705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 144.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too much error 37 models\n",
      "random seed 2\n",
      "baseline training_loss 2935.418350904594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too much error 39 models\n",
      "random seed 3\n",
      "baseline training_loss 2999.6081504893073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 98.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too much error 42 models\n",
      "random seed 4\n",
      "baseline training_loss 3019.967853428894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 102.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too much error 37 models\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "num_weights = len(features) + 1\n",
    "for random_seed in range(num_random_seeds):\n",
    "    print(\"random seed\", random_seed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state=random_seed)\n",
    "\n",
    "    cost = X_test[\"cost_t\"].to_numpy()\n",
    "    gagne = X_test[\"gagne_sum_t\"].to_numpy()\n",
    "    person_id = X_test['person_id'].to_numpy()\n",
    "\n",
    "    X_train = X_train.drop(columns=other_variables).to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    X_val = X_val.drop(columns=other_variables).to_numpy()\n",
    "    y_val = y_val.to_numpy()\n",
    "    X_test = X_test.drop(columns=other_variables).to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "    # Orthonormalize the training matrix\n",
    "    intercept_idx = 0\n",
    "    X_train = np.insert(X_train, intercept_idx, 1.0, axis=1)\n",
    "    q, r = sp.linalg.qr(X_train) # q is the orthonormalized basis, r is the upper triangular\n",
    "    q = q[:,:num_weights] # keep only columns of q that actually get multiplied\n",
    "    r = r[:num_weights] # make r a square matrix\n",
    "\n",
    "    r_inverse = sp.linalg.inv(r) # q = q * r * r' = X * r'\n",
    "    X_test = np.insert(X_test, intercept_idx, 1.0, axis=1)\n",
    "    X_ortho_test = X_test @ r_inverse\n",
    "    X_val = np.insert(X_val, intercept_idx, 1.0, axis=1)\n",
    "    X_ortho_val = X_val @ r_inverse\n",
    "\n",
    "    predictions = {}\n",
    "    training_loss = {}\n",
    "    validation_loss = {}\n",
    "    baseline_weights = get_baseline_model_coefficients(q, y_train)\n",
    "    baseline_loss = rss_loss(y_train, np.dot(q, baseline_weights))\n",
    "    \n",
    "    print(f\"baseline training_loss {baseline_loss}\")\n",
    "    count = 0\n",
    "    for i in tqdm(range(num_perturbed_models)):\n",
    "        perturbed_weights = get_perturbed_weights(baseline_weights, EPSILON)\n",
    "        predictions[f'm_{i+1}'] = np.dot(X_ortho_test, perturbed_weights)\n",
    "        t_loss = rss_loss(y_train, np.dot(q, perturbed_weights))\n",
    "        if t_loss > baseline_loss + EPSILON:\n",
    "            count += 1\n",
    "            # print(f\"oh noooooooooooooo {t_loss} too big\")\n",
    "        training_loss[f'm_{i+1}'] = log_loss(y_train, np.dot(q, perturbed_weights))\n",
    "        validation_loss[f'm_{i+1}'] = log_loss(y_val, np.dot(X_ortho_val, perturbed_weights))\n",
    "\n",
    "    print(f\"too much error {count} models\")\n",
    "                            \n",
    "    predictions_df = pd.concat([\n",
    "        pd.DataFrame(predictions),\n",
    "        pd.DataFrame(training_loss, index=[0]),\n",
    "        pd.DataFrame(validation_loss, index=[0])]).reset_index(drop=True)\n",
    "    \n",
    "    predictions_df[\"y\"] = np.concatenate([y_test, [np.nan, np.nan]])\n",
    "    predictions_df[\"person_id\"] = np.concatenate([person_id, [-2, -1]]) # -1 indicates validation loss, -2 indicates training loss\n",
    "    predictions_df['cost_t'] = np.concatenate([cost, [np.nan, np.nan]]) \n",
    "    predictions_df['gagne_sum_t'] = np.concatenate([gagne, [np.nan, np.nan]])\n",
    "    predictions_df[\"seed\"] = random_seed\n",
    "\n",
    "    output.append(predictions_df)\n",
    "    \n",
    "output = pd.concat(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_1</th>\n",
       "      <th>m_2</th>\n",
       "      <th>m_3</th>\n",
       "      <th>m_4</th>\n",
       "      <th>m_5</th>\n",
       "      <th>m_6</th>\n",
       "      <th>m_7</th>\n",
       "      <th>m_8</th>\n",
       "      <th>m_9</th>\n",
       "      <th>m_10</th>\n",
       "      <th>y</th>\n",
       "      <th>person_id</th>\n",
       "      <th>cost_t</th>\n",
       "      <th>gagne_sum_t</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.019835</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>-0.020386</td>\n",
       "      <td>-0.019915</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>-0.020007</td>\n",
       "      <td>-0.019889</td>\n",
       "      <td>-0.019885</td>\n",
       "      <td>-0.019995</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2545</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.080950</td>\n",
       "      <td>0.080478</td>\n",
       "      <td>0.080819</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.080616</td>\n",
       "      <td>0.080869</td>\n",
       "      <td>0.080984</td>\n",
       "      <td>0.080887</td>\n",
       "      <td>0.080838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8198</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.072258</td>\n",
       "      <td>-0.072819</td>\n",
       "      <td>-0.073480</td>\n",
       "      <td>-0.072972</td>\n",
       "      <td>-0.072733</td>\n",
       "      <td>-0.073173</td>\n",
       "      <td>-0.072908</td>\n",
       "      <td>-0.073571</td>\n",
       "      <td>-0.073039</td>\n",
       "      <td>-0.072832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46461</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.208993</td>\n",
       "      <td>-0.208892</td>\n",
       "      <td>-0.207873</td>\n",
       "      <td>-0.208485</td>\n",
       "      <td>-0.208466</td>\n",
       "      <td>-0.208490</td>\n",
       "      <td>-0.208448</td>\n",
       "      <td>-0.208626</td>\n",
       "      <td>-0.208503</td>\n",
       "      <td>-0.208484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30620</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107347</td>\n",
       "      <td>0.106343</td>\n",
       "      <td>0.107324</td>\n",
       "      <td>0.107374</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.107556</td>\n",
       "      <td>0.107395</td>\n",
       "      <td>0.107287</td>\n",
       "      <td>0.107387</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47418</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        m_1       m_2       m_3       m_4       m_5       m_6       m_7  \\\n",
       "0 -0.019835 -0.020067 -0.020386 -0.019915 -0.020128 -0.020007 -0.019889   \n",
       "1  0.080933  0.080950  0.080478  0.080819  0.080785  0.080616  0.080869   \n",
       "2 -0.072258 -0.072819 -0.073480 -0.072972 -0.072733 -0.073173 -0.072908   \n",
       "3 -0.208993 -0.208892 -0.207873 -0.208485 -0.208466 -0.208490 -0.208448   \n",
       "4  0.107347  0.106343  0.107324  0.107374  0.107178  0.107556  0.107395   \n",
       "\n",
       "        m_8       m_9      m_10    y  person_id    cost_t  gagne_sum_t  seed  \n",
       "0 -0.019885 -0.019995 -0.019854  0.0       2545  0.009628          1.0     0  \n",
       "1  0.080984  0.080887  0.080838  0.0       8198  0.004905          2.0     0  \n",
       "2 -0.073571 -0.073039 -0.072832  0.0      46461  0.009446          0.0     0  \n",
       "3 -0.208626 -0.208503 -0.208484  0.0      30620  0.002361          0.0     0  \n",
       "4  0.107287  0.107387  0.106992  0.0      47418  0.003996          2.0     0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(prediction_output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11507308429942796\n",
      "0.11507999056767682\n",
      "0.1150663174449882\n",
      "0.11509745879770553\n",
      "0.11506694099084161\n",
      "0.11505165482684833\n",
      "0.11508433979567395\n",
      "0.11507781670692932\n",
      "0.115089960599257\n",
      "0.11505346600623309\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    se = np.mean((output['m_'+str(i+1)] - output['y']) ** 2)\n",
    "    print(se)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
