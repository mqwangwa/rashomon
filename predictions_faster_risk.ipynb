{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fasterrisk.binarization_util import convert_continuous_df_to_binary_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_random_seeds = 1\n",
    "\n",
    "sparsity = [5, 6, 7, 8, 9, 10]\n",
    "coeff_bounds = [5, 10, 15]\n",
    "\n",
    "TARGET_VARIABLE = \"qualified_gagne_2\"\n",
    "prediction_output = \"predictions/obermeyer/fasterrisk_\"+TARGET_VARIABLE+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"data/obermeyer/obermeyer_data_cleaned.csv\"\n",
    "features = ['dem_female', 'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1', 'dem_age_band_45-54_tm1',\n",
    "            'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1', 'hypertension_elixhauser_tm1', 'cost_dialysis_tm1',\n",
    "            'cost_emergency_tm1', 'cost_home_health_tm1', 'cost_ip_medical_tm1', 'cost_ip_surgical_tm1', 'cost_laboratory_tm1',\n",
    "            'cost_op_primary_care_tm1', 'cost_op_specialists_tm1', 'cost_op_surgery_tm1', 'cost_other_tm1', 'cost_pharmacy_tm1',\n",
    "            'cost_physical_therapy_tm1', 'cost_radiology_tm1', 'gagne_sum_tm1']\n",
    "other_variables = ['person_id', 'gagne_sum_t', 'cost_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/yt_9nm1s5ngbsytz47vfxfjh0000gn/T/ipykernel_97357/684635102.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[TARGET_VARIABLE] = (y[TARGET_VARIABLE]*2)-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_source)\n",
    "X = df[features]\n",
    "y = df[[TARGET_VARIABLE]+other_variables]\n",
    "y.loc[:, TARGET_VARIABLE] = (y.loc[:, TARGET_VARIABLE]*2)-1\n",
    "\n",
    "X_binarized_df, featureIndex_to_groupIndex = convert_continuous_df_to_binary_df(X, get_featureIndex_to_groupIndex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 0\n",
      "5 5 We generate 84 risk score models from the sparse diverse pool\n",
      "0.2896223875720162\n",
      "\n",
      "5 10 We generate 100 risk score models from the sparse diverse pool\n",
      "0.2897917168263317\n",
      "\n",
      "5 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.28967314827369384\n",
      "\n",
      "6 5 We generate 84 risk score models from the sparse diverse pool\n",
      "0.2892845315626386\n",
      "\n",
      "6 10 We generate 100 risk score models from the sparse diverse pool\n",
      "0.2880386389099772\n",
      "\n",
      "6 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.288060961078057\n",
      "\n",
      "7 5 We generate 82 risk score models from the sparse diverse pool\n",
      "0.2892658217783924\n",
      "\n",
      "7 10 We generate 98 risk score models from the sparse diverse pool\n",
      "0.2868125495492103\n",
      "\n",
      "7 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.28665173505892255\n",
      "\n",
      "8 5 We generate 86 risk score models from the sparse diverse pool\n",
      "0.2871914591557787\n",
      "\n",
      "8 10 We generate 100 risk score models from the sparse diverse pool\n",
      "0.28556188268887583\n",
      "\n",
      "8 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.28539196822126933\n",
      "\n",
      "9 5 We generate 72 risk score models from the sparse diverse pool\n",
      "0.2864969366152309\n",
      "\n",
      "9 10 We generate 100 risk score models from the sparse diverse pool\n",
      "0.2848142540350601\n",
      "\n",
      "9 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.28470548518043587\n",
      "\n",
      "10 5 We generate 73 risk score models from the sparse diverse pool\n",
      "0.285737759160511\n",
      "\n",
      "10 10 We generate 98 risk score models from the sparse diverse pool\n",
      "0.28453684302846993\n",
      "\n",
      "10 15 We generate 100 risk score models from the sparse diverse pool\n",
      "0.2841087715061109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for random_seed in range(num_random_seeds):\n",
    "    print(\"Random Seed:\", random_seed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_binarized_df, y, test_size=0.20, random_state=random_seed)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_seed)\n",
    "    \n",
    "    cost = y_test[\"cost_t\"].to_numpy()\n",
    "    gagne = y_test[\"gagne_sum_t\"].to_numpy()\n",
    "    person_id = y_test['person_id'].to_numpy()\n",
    "\n",
    "    y_train = y_train[TARGET_VARIABLE].to_numpy()\n",
    "    y_val = y_val[TARGET_VARIABLE].to_numpy()\n",
    "    y_test = y_test[TARGET_VARIABLE].to_numpy()\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_val = X_val.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "\n",
    "    predictions = {}\n",
    "    training_loss = {}\n",
    "    validation_loss = {}\n",
    "    i = 0\n",
    "    \n",
    "    for k in sparsity:\n",
    "        for b in coeff_bounds:\n",
    "            RiskScoreOptimizer_m = RiskScoreOptimizer(X = X_train, y = y_train, k = k, lb = -b, ub = b,\n",
    "                                                     select_top_m=100, parent_size=20, num_ray_search=40)\n",
    "                                              #group_sparsity = 3, \\\n",
    "                                              #featureIndex_to_groupIndex = featureIndex_to_groupIndex)    \n",
    "            RiskScoreOptimizer_m.optimize()\n",
    "            multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "\n",
    "            print(k, b, \"We generate {} risk score models from the sparse diverse pool\".format(len(multipliers)))\n",
    "\n",
    "            val_loss = []\n",
    "            for model_index in range(len(multipliers)):\n",
    "                multiplier = multipliers[model_index]\n",
    "                intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "                coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "                RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "                \n",
    "                predictions[f'm_{i+1}'] = RiskScoreClassifier_m.predict_prob(X_test)\n",
    "                training_loss[f'm_{i+1}'] = log_loss(y_train, RiskScoreClassifier_m.predict_prob(X_train))\n",
    "                validation_loss[f'm_{i+1}'] = log_loss(y_val, RiskScoreClassifier_m.predict_prob(X_val))\n",
    "                val_loss.append(log_loss(y_val, RiskScoreClassifier_m.predict_prob(X_val)))\n",
    "                i += 1\n",
    "            print(np.mean(val_loss))\n",
    "            print()\n",
    "            \n",
    "    predictions_df = pd.concat([\n",
    "        pd.DataFrame(predictions),\n",
    "        pd.DataFrame(training_loss, index=[0]),\n",
    "        pd.DataFrame(validation_loss, index=[0])]).reset_index(drop=True)\n",
    "    \n",
    "    predictions_df[\"y\"] = np.concatenate([y_test, [np.nan, np.nan]])\n",
    "    predictions_df[\"person_id\"] = np.concatenate([person_id, [-2, -1]]) # -1 indicates validation loss, -2 indicates training loss\n",
    "    predictions_df['cost_t'] = np.concatenate([cost, [np.nan, np.nan]]) \n",
    "    predictions_df['gagne_sum_t'] = np.concatenate([gagne, [np.nan, np.nan]])\n",
    "    predictions_df[\"seed\"] = random_seed\n",
    "\n",
    "    output.append(predictions_df)\n",
    "    \n",
    "output = pd.concat(output)\n",
    "for c in output.columns:\n",
    "    if c.startswith(\"m_\"):\n",
    "        output[c] = output[c].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_1</th>\n",
       "      <th>m_2</th>\n",
       "      <th>m_3</th>\n",
       "      <th>m_4</th>\n",
       "      <th>m_5</th>\n",
       "      <th>m_6</th>\n",
       "      <th>m_7</th>\n",
       "      <th>m_8</th>\n",
       "      <th>m_9</th>\n",
       "      <th>m_10</th>\n",
       "      <th>...</th>\n",
       "      <th>m_1673</th>\n",
       "      <th>m_1674</th>\n",
       "      <th>m_1675</th>\n",
       "      <th>m_1676</th>\n",
       "      <th>m_1677</th>\n",
       "      <th>y</th>\n",
       "      <th>person_id</th>\n",
       "      <th>cost_t</th>\n",
       "      <th>gagne_sum_t</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111365</td>\n",
       "      <td>0.109609</td>\n",
       "      <td>0.114006</td>\n",
       "      <td>0.109575</td>\n",
       "      <td>0.112977</td>\n",
       "      <td>0.092255</td>\n",
       "      <td>0.112993</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.112886</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186702</td>\n",
       "      <td>0.186631</td>\n",
       "      <td>0.186546</td>\n",
       "      <td>0.186536</td>\n",
       "      <td>0.186467</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2545</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799726</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.796891</td>\n",
       "      <td>0.801664</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>0.797975</td>\n",
       "      <td>0.797985</td>\n",
       "      <td>0.798090</td>\n",
       "      <td>0.798091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773174</td>\n",
       "      <td>0.773242</td>\n",
       "      <td>0.773324</td>\n",
       "      <td>0.773334</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8198</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111365</td>\n",
       "      <td>0.109609</td>\n",
       "      <td>0.114006</td>\n",
       "      <td>0.109575</td>\n",
       "      <td>0.112977</td>\n",
       "      <td>0.092255</td>\n",
       "      <td>0.112993</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.112886</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079246</td>\n",
       "      <td>0.079189</td>\n",
       "      <td>0.079121</td>\n",
       "      <td>0.079113</td>\n",
       "      <td>0.079058</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>46461</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024627</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>30620</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.799726</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.796891</td>\n",
       "      <td>0.801664</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>0.797975</td>\n",
       "      <td>0.797985</td>\n",
       "      <td>0.798090</td>\n",
       "      <td>0.798091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813298</td>\n",
       "      <td>0.813369</td>\n",
       "      <td>0.813454</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.813533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47418</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.885994</td>\n",
       "      <td>0.942321</td>\n",
       "      <td>0.887023</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.887007</td>\n",
       "      <td>0.887016</td>\n",
       "      <td>0.887114</td>\n",
       "      <td>0.887115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900910</td>\n",
       "      <td>0.900972</td>\n",
       "      <td>0.901047</td>\n",
       "      <td>0.901056</td>\n",
       "      <td>0.901117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16951</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>0.799726</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.796891</td>\n",
       "      <td>0.801664</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.681817</td>\n",
       "      <td>0.797975</td>\n",
       "      <td>0.797985</td>\n",
       "      <td>0.798090</td>\n",
       "      <td>0.798091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773174</td>\n",
       "      <td>0.773242</td>\n",
       "      <td>0.773324</td>\n",
       "      <td>0.773334</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35677</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>0.031755</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039603</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>0.039513</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>27577</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>0.280880</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.281237</td>\n",
       "      <td>0.281314</td>\n",
       "      <td>0.281352</td>\n",
       "      <td>0.281358</td>\n",
       "      <td>0.281374</td>\n",
       "      <td>0.281375</td>\n",
       "      <td>0.281410</td>\n",
       "      <td>0.281439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275322</td>\n",
       "      <td>0.275357</td>\n",
       "      <td>0.275361</td>\n",
       "      <td>0.275361</td>\n",
       "      <td>0.275366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.288359</td>\n",
       "      <td>0.288729</td>\n",
       "      <td>0.288177</td>\n",
       "      <td>0.289140</td>\n",
       "      <td>0.288657</td>\n",
       "      <td>0.289187</td>\n",
       "      <td>0.289122</td>\n",
       "      <td>0.289259</td>\n",
       "      <td>0.289248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283889</td>\n",
       "      <td>0.283342</td>\n",
       "      <td>0.283356</td>\n",
       "      <td>0.283352</td>\n",
       "      <td>0.283486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9759 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           m_1       m_2       m_3       m_4       m_5       m_6       m_7  \\\n",
       "0     0.111365  0.109609  0.114006  0.109575  0.112977  0.092255  0.112993   \n",
       "1     0.799726  0.801626  0.796891  0.801664  0.797992  0.681817  0.797975   \n",
       "2     0.111365  0.109609  0.114006  0.109575  0.112977  0.092255  0.112993   \n",
       "3     0.030429  0.029563  0.016288  0.029546  0.031235  0.021654  0.031243   \n",
       "4     0.799726  0.801626  0.796891  0.801664  0.797992  0.681817  0.797975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9754  0.888635  0.890391  0.885994  0.942321  0.887023  0.821167  0.887007   \n",
       "9755  0.799726  0.801626  0.796891  0.801664  0.797992  0.681817  0.797975   \n",
       "9756  0.030429  0.029563  0.031755  0.029546  0.031235  0.021654  0.031243   \n",
       "9757  0.280880  0.281003  0.281237  0.281314  0.281352  0.281358  0.281374   \n",
       "9758  0.287703  0.288359  0.288729  0.288177  0.289140  0.288657  0.289187   \n",
       "\n",
       "           m_8       m_9      m_10  ...    m_1673    m_1674    m_1675  \\\n",
       "0     0.112984  0.112886  0.112885  ...  0.186702  0.186631  0.186546   \n",
       "1     0.797985  0.798090  0.798091  ...  0.773174  0.773242  0.773324   \n",
       "2     0.112984  0.112886  0.112885  ...  0.079246  0.079189  0.079121   \n",
       "3     0.031239  0.031189  0.031189  ...  0.024627  0.024599  0.024566   \n",
       "4     0.797985  0.798090  0.798091  ...  0.813298  0.813369  0.813454   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9754  0.887016  0.887114  0.887115  ...  0.900910  0.900972  0.901047   \n",
       "9755  0.797985  0.798090  0.798091  ...  0.773174  0.773242  0.773324   \n",
       "9756  0.031239  0.031189  0.031189  ...  0.039603  0.039565  0.039519   \n",
       "9757  0.281375  0.281410  0.281439  ...  0.275322  0.275357  0.275361   \n",
       "9758  0.289122  0.289259  0.289248  ...  0.283889  0.283342  0.283356   \n",
       "\n",
       "        m_1676    m_1677    y  person_id  cost_t  gagne_sum_t  seed  \n",
       "0     0.186536  0.186467 -1.0       2545  5300.0          1.0     0  \n",
       "1     0.773334  0.773400  1.0       8198  2700.0          2.0     0  \n",
       "2     0.079113  0.079058 -1.0      46461  5200.0          0.0     0  \n",
       "3     0.024562  0.024535 -1.0      30620  1300.0          0.0     0  \n",
       "4     0.813464  0.813533  1.0      47418  2200.0          2.0     0  \n",
       "...        ...       ...  ...        ...     ...          ...   ...  \n",
       "9754  0.901056  0.901117  1.0      16951  3600.0          5.0     0  \n",
       "9755  0.773334  0.773400  1.0      35677  4100.0          2.0     0  \n",
       "9756  0.039513  0.039476 -1.0      27577  3200.0          1.0     0  \n",
       "9757  0.275361  0.275366  NaN         -2     NaN          NaN     0  \n",
       "9758  0.283352  0.283486  NaN         -1     NaN          NaN     0  \n",
       "\n",
       "[9759 rows x 1682 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.to_csv(prediction_output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
