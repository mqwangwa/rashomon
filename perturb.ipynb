{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### based on [perturb_all.py](https://github.com/HsiangHsu/rashomon-capacity/blob/main/awp/adult-compas-hsls/perturb-all.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from time import localtime, strftime\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "## accelerating\n",
    "from itertools import islice\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "## custom packages\n",
    "from training_MLP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.30\n",
    "NREPEAT = 1 # number of train-test splits\n",
    "NMODELS = 1 # number of models per split\n",
    "NNEURON = 20 # should be 100 or 200\n",
    "NLAYER = 5\n",
    "NEPOCH = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAINLR = 0.001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"data/obermeyer/obermeyer_data_cleaned.csv\"\n",
    "prediction_output = \"predictions/obermeyer/awp_nn.csv\"\n",
    "target_variable = \"cost_t\"\n",
    "features = ['dem_female', 'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1', 'dem_age_band_45-54_tm1',\n",
    "            'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1', 'hypertension_elixhauser_tm1', 'cost_dialysis_tm1',\n",
    "            'cost_emergency_tm1', 'cost_home_health_tm1', 'cost_ip_medical_tm1', 'cost_ip_surgical_tm1', 'cost_laboratory_tm1',\n",
    "            'cost_op_primary_care_tm1', 'cost_op_specialists_tm1', 'cost_op_surgery_tm1', 'cost_other_tm1', 'cost_pharmacy_tm1',\n",
    "            'cost_physical_therapy_tm1', 'cost_radiology_tm1', 'gagne_sum_tm1', 'person_id', 'threshold_25', 'threshold_50', 'threshold_75']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_source)\n",
    "X = df[features]\n",
    "y = df[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X.shape = (48784, 27), y.shape = (48784,), nclass = 963\n",
      "\n",
      " X_train.shape = 34148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = int(np.round(X.shape[0]*(1-TEST_SPLIT)))-1\n",
    "nclass = len(set(y))\n",
    "ntest = X.shape[0]-n\n",
    "\n",
    "print(' X.shape = {}, y.shape = {}, nclass = {}\\n'.format(X.shape, y.shape, nclass))\n",
    "print(' X_train.shape = {}\\n'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_loss = np.zeros((NREPEAT, ))\n",
    "base_train_acc = np.zeros((NREPEAT, ))\n",
    "base_test_loss = np.zeros((NREPEAT, ))\n",
    "base_test_acc = np.zeros((NREPEAT, ))\n",
    "\n",
    "rashomon_prob = np.zeros((NREPEAT, ntest, nclass, nclass))\n",
    "rashomon_loss = np.zeros((NREPEAT, ntest, nclass))\n",
    "sample_train_cap = np.zeros((NREPEAT, ntest))\n",
    "y_train_all = np.zeros((NREPEAT, ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neural_network(X_train, y_train, X_test, random_seed, bootstrap_size=0.5):\n",
    "    ## use random seed\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    ## define network architexture\n",
    "    nfeature = X_train.shape[1]\n",
    "    nclass = 1 ## len(set(y_train))\n",
    "    nn_arch = [nfeature, nclass, NNEURON, NLAYER]\n",
    "\n",
    "    ## create and train model\n",
    "    base_model = MLP(nn_arch).to(DEVICE)\n",
    "    criterion = nn.MSELoss() ## nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(base_model.parameters(), lr=TRAINLR, momentum=MOMENTUM)\n",
    "    base_model = train_model(base_model, X_train, y_train, NEPOCH, optimizer, criterion, DEVICE)\n",
    "\n",
    "    ## get allocations\n",
    "    base_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model(torch.Tensor(X_test).to(DEVICE))  # Predictions/scores\n",
    "        outputs_np = outputs.cpu().numpy()  # Detach and move to CPU as numpy array\n",
    "    all_same = np.all(outputs_np == outputs_np[0, :], axis=0)\n",
    "    print(\"Are all rows the same?\", all_same.all()) \n",
    "    print(outputs_np)  # Print scores\n",
    "    print(outputs_np.shape)\n",
    "    return outputs_np[0, :]  # Return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 0\n",
      "(14636,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all rows the same? False\n",
      "[[-0.07817269]\n",
      " [-0.07793552]\n",
      " [-0.07844877]\n",
      " ...\n",
      " [-0.07863903]\n",
      " [-0.07829844]\n",
      " [-0.07865667]]\n",
      "(14636, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (14636) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(predictions)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m     26\u001b[0m predictions_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m---> 27\u001b[0m \u001b[43mpredictions_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y_test\n\u001b[1;32m     28\u001b[0m predictions_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_idx \n\u001b[1;32m     29\u001b[0m predictions_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m random_seed\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4298\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4512\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4504\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4505\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4510\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4512\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4515\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4516\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4517\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4518\u001b[0m     ):\n\u001b[1;32m   4519\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4520\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:5253\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5253\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5254\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5256\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5261\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (14636) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for random_seed in range(NREPEAT):\n",
    "    print(\"random seed\", random_seed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random_seed)\n",
    "    threshold_25 = X_test['threshold_25'].to_numpy()\n",
    "    threshold_50 = X_test['threshold_50'].to_numpy()\n",
    "    threshold_75 = X_test['threshold_75'].to_numpy()\n",
    "    test_idx = X_test['person_id'].to_numpy()\n",
    "    # print(test_idx.isna().sum())\n",
    "    X_train = X_train.drop(columns=['person_id']).to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    X_test = X_test.drop(columns=['person_id']).to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    print(y_test.shape)\n",
    "\n",
    "    predictions = []\n",
    "    columns = []\n",
    "    accuracy = []\n",
    "    for i in tqdm(range(NMODELS)):\n",
    "        columns.append(f'm_{i+1}')\n",
    "        scores = get_neural_network(X_train, y_train, X_test, random_seed=i, bootstrap_size=0.5)\n",
    "        predictions.append(scores)\n",
    "        accuracy.append(float((np.round(scores)==y_test).sum() / len(y_test)))\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions).transpose()\n",
    "    predictions_df.columns=columns\n",
    "    predictions_df[\"y\"] = y_test\n",
    "    predictions_df[\"idx\"] = test_idx \n",
    "    predictions_df[\"seed\"] = random_seed\n",
    "    predictions_df['threshold_25'] = threshold_25\n",
    "    predictions_df['threshold_50'] = threshold_50\n",
    "    predictions_df['threshold_75'] = threshold_75\n",
    "    output.append(predictions_df)\n",
    "output = pd.concat(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
